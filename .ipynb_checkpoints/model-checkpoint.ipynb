{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "passive-scoop",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf # pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "boxed-syndication",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "nasty-pension",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train),(x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "clear-paraguay",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "optical-acting",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "opened-newspaper",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x21a1e48a308>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_train = tf.keras.utils.normalize (x_train, axis = 1)\n",
    "x_test = tf.keras.utils.normalize(x_test, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "sticky-heritage",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Samples dimension (60000, 28, 28, 1)\n",
      "Testing Samples dimension (10000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # pip install numpy\n",
    "IMG_SIZE=28\n",
    "x_trainr= np.array(x_train).reshape(-1, IMG_SIZE, IMG_SIZE,1)\n",
    "x_testr= np.array(x_test).reshape (-1, IMG_SIZE, IMG_SIZE,1)\n",
    "print (\"Training Samples dimension\",x_trainr.shape)\n",
    "print (\"Testing Samples dimension\",x_testr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "wicked-dollar",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "experienced-offer",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Creating a neural network now\n",
    "model = Sequential ()\n",
    "##### First Convolution Layer e 1 2 3\n",
    "model.add(Conv2D(64, (3,3), input_shape = x_trainr.shape[1:])) ### only for first convolution layer to mention input layer size\n",
    "model.add (Activation(\"relu\"))## activation funtion to make it non-linear, <e, remove, >0\n",
    "model.add (MaxPooling2D(pool_size=(2,2)))\n",
    "model.add (Conv2D(64, (3,3))) ## 2nd Convolution Layer\n",
    "model.add(Activation(\"relu\")) ## activation funtion\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))## MAxpooling\n",
    "##### 3rd Convolution Layer\n",
    "model.add (Conv2D(64, (3,3))) # 24*24\n",
    "model.add (Activation(\"relu\"))\n",
    "model.add (MaxPooling2D(pool_size=(2,2)))\n",
    "#### FuLly Connected Layer # 1 20x20= 400\n",
    "model.add (Flatten()) ### before using fully connected Layer, need to be flatten so that 2D to 1D\n",
    "model.add (Dense (64)) #\n",
    "model.add (Activation(\"relu\"))\n",
    "#### FuLly Connected Layer # 2\n",
    "model.add (Dense(32))\n",
    "model.add(Activation(\"relu\"))\n",
    "#### Last Fully Connected Layer , output must be equal to number of classes, 10 (0-9)\n",
    "model.add (Dense(10)) ## this Last dense Layer must be equal to 10\n",
    "model.add (Activation('softmax')) ### activation function is changed to Softmax (Class probabilites )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "serious-vatican",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss =\"sparse_categorical_crossentropy\", optimizer =\"adam\", metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "insured-village",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1313/1313 [==============================] - 38s 29ms/step - loss: 0.6785 - accuracy: 0.7741 - val_loss: 0.1209 - val_accuracy: 0.9624\n",
      "Epoch 2/5\n",
      "1313/1313 [==============================] - 45s 34ms/step - loss: 0.1040 - accuracy: 0.9677 - val_loss: 0.0879 - val_accuracy: 0.9724\n",
      "Epoch 3/5\n",
      "1313/1313 [==============================] - 30s 23ms/step - loss: 0.0700 - accuracy: 0.9782 - val_loss: 0.0664 - val_accuracy: 0.9792\n",
      "Epoch 4/5\n",
      "1313/1313 [==============================] - 32s 25ms/step - loss: 0.0536 - accuracy: 0.9828 - val_loss: 0.0630 - val_accuracy: 0.9816\n",
      "Epoch 5/5\n",
      "1313/1313 [==============================] - 34s 26ms/step - loss: 0.0393 - accuracy: 0.9875 - val_loss: 0.0586 - val_accuracy: 0.9830\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x21a190a6548>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_trainr,y_train, epochs=5, validation_split = 0.3) ## Training my model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "surface-utilization",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 5ms/step - loss: 0.0543 - accuracy: 0.9836\n",
      "Test Loss on 10,000 test samples 0.05432405322790146\n",
      "Validation Accuracy on 10,000 test samples 0.9836000204086304\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(x_testr, y_test)\n",
    "print (\"Test Loss on 10,000 test samples\",test_loss )\n",
    "print (\"Validation Accuracy on 10,000 test samples\",test_acc )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
